import streamlit as st
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.messages import ChatMessage
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.prompts import load_prompt
from langchain_core.prompts.few_shot import FewShotPromptTemplate
import json


st.set_page_config(page_title="DAPS ğŸ’¬", page_icon="ğŸ’¬")
st.title("DAPS ğŸ’¬")

if "messages" not in st.session_state:
    st.session_state["messages"] = []


def print_history():
    for msg in st.session_state["messages"]:
        st.chat_message(msg.role).write(msg.content)


def add_history(role, content):
    st.session_state["messages"].append(ChatMessage(role=role, content=content))


# ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
def create_chain(prompt, model):
    llm = ChatOpenAI(
        temperature=0.1,  # ì°½ì˜ì„±
        model_name="gpt-4o-mini",  # ëª¨ë¸ëª… "gpt-4o-mini" vs "o3-mini"
    )
    # outputì„ JSON í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•˜ë„ë¡ ë³€ê²½
    chain = prompt | llm | JsonOutputParser()
    return chain

# ì˜ˆì œ í…œí”Œë¦¿: LLMì´ answerì™€ sentimentë¥¼ JSONìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ í•¨
example_prompt = PromptTemplate.from_template(
    '{"answer": "{answer}", "sentiment": {sentiment}}'
)

prompt = load_prompt("prompts/default.yaml", encoding="utf8")
try:
    with open("examples.json", "r", encoding="utf8") as f: # ì¶”í›„ DBë¡œ ëŒ€ì²´
        examples = json.load(f)
    prompt = FewShotPromptTemplate(
            examples=examples,
            example_prompt=example_prompt,
            suffix=(
                "Question:\n{question}\n"
                "Provide the answer and a sentiment score (1-10) in JSON format."
            ),
            input_variables=["question"],
        )
except FileNotFoundError:
    pass
st.session_state["chain"] = create_chain(prompt, "o3-mini")

print_history()


if user_input := st.chat_input():
    add_history("user", user_input)
    st.chat_message("user").write(user_input)
    with st.chat_message("assistant"):
        chat_container = st.empty()

        stream_response = st.session_state["chain"].stream({"question": user_input})
        ai_result_text = ""
        for chunk in stream_response:
            ai_result_text += chunk
            # ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µ ì§„í–‰ ìƒí™© í‘œì‹œ
            chat_container.markdown(ai_result_text)
        # ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚œ í›„ ìµœì¢… ê²°ê³¼ ì¶œë ¥ ë° íŒŒì‹± ì‹œë„
        print(f"ai_result_text: {ai_result_text}")
        try:
            result = json.loads(ai_result_text)
        except json.JSONDecodeError as e:
            print("JSON íŒŒì‹± ì˜¤ë¥˜:", e)
            result = {}
        ai_answer = result.get("answer", "")
        sentiment = result.get("sentiment", 0)
        add_history("ai", ai_answer)

    # ì˜ˆì‹œ: chain ì‹¤í–‰ í›„ ë°›ëŠ” ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ìƒˆ í•­ëª© ìƒì„±
    new_entry = {
        "question": user_input,
        "answer": ai_answer,      
        "sentiment": sentiment
    }

    # ê¸°ì¡´ì˜ examples.json íŒŒì¼ì„ ì½ê³  ìƒˆ í•­ëª©ì„ ì¶”ê°€í•œ í›„ ë‹¤ì‹œ ì €ì¥í•©ë‹ˆë‹¤.
    try:
        with open("examples.json", "r", encoding="utf8") as f:
            data = json.load(f)
    except FileNotFoundError:
        data = []  # íŒŒì¼ì´ ì—†ë‹¤ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±

    data.append(new_entry)

    with open("examples.json", "w", encoding="utf8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
